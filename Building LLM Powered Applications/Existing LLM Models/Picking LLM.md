### Factors
* Size and performance
	* Higher tokens is usually more performant
	* But requires more compute and memory
		* Also higher latency and cost
* Cost and hosting strategy
	* Cost for model consumption
		* e.g. API calls / tokens consumed
	* Cost for model hosting
		* Hosted on a hyperscaler (?)
		* Consumed by REST API
* Customization
	* Fine tuning
	* Training from scratch
* Domain specific capabilities